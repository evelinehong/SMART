{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "from src.train_and_evaluate import *\n",
    "from src.models import *\n",
    "import time\n",
    "import torch.optim\n",
    "from src.expressions_transfer import *\n",
    "import json\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path,'r',encoding=\"utf-8\") as f:\n",
    "        file = json.load(f)\n",
    "    return file\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "embedding_size = 128\n",
    "hidden_size = 512\n",
    "n_epochs = 80\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-5\n",
    "beam_size = 5\n",
    "n_layers = 2\n",
    "ori_path = './data/new_'\n",
    "prefix = '23k_processed.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Transfer numbers...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_train_test_fold(ori_path,prefix,data,pairs,group):\n",
    "    mode_train = 'train'\n",
    "    mode_valid = 'valid'\n",
    "    mode_test = 'test'\n",
    "    train_path = ori_path + mode_train + prefix\n",
    "    valid_path = ori_path + mode_valid + prefix\n",
    "    test_path = ori_path + mode_test + prefix\n",
    "    train = read_json(train_path)\n",
    "    train_id = [item['id'] for item in train]\n",
    "    valid = read_json(valid_path)\n",
    "    valid_id = [item['id'] for item in valid]\n",
    "    test = read_json(test_path)\n",
    "    test_id = [item['id'] for item in test]\n",
    "    train_fold = []\n",
    "    valid_fold = []\n",
    "    test_fold = []\n",
    "    for item,pair,g in zip(data, pairs, group):\n",
    "        pair = list(pair)\n",
    "        pair.append(g['group_num'])\n",
    "        pair.append(item['id'])\n",
    "        pair = tuple(pair)\n",
    "        if item['id'] in train_id:\n",
    "            train_fold.append(pair)\n",
    "        elif item['id'] in test_id:\n",
    "            test_fold.append(pair)\n",
    "        else:\n",
    "            valid_fold.append(pair)\n",
    "    return train_fold, test_fold, valid_fold\n",
    "\n",
    "def change_num(num):\n",
    "    new_num = []\n",
    "    for item in num:\n",
    "        if '/' in item:\n",
    "            new_str = item.split(')')[0]\n",
    "            new_str = new_str.split('(')[1]\n",
    "            a = float(new_str.split('/')[0])\n",
    "            b = float(new_str.split('/')[1])\n",
    "            value = a/b\n",
    "            new_num.append(value)\n",
    "        elif '%' in item:\n",
    "            value = float(item[0:-1])/100\n",
    "            new_num.append(value)\n",
    "        else:\n",
    "            new_num.append(float(item))\n",
    "    return new_num\n",
    "\n",
    "\n",
    "#data = load_raw_data(\"data/Math_23K.json\")\n",
    "#group_data = read_json(\"data/Math_23K_processed.json\")\n",
    "\n",
    "data = load_raw_data(\"data/new_Math_23K.json\")\n",
    "group_data =  read_json(\"data/Math_23K_processed.json\")\n",
    "\n",
    "pairs, generate_nums, copy_nums = transfer_num(data)\n",
    "\n",
    "temp_pairs = []\n",
    "for p in pairs:\n",
    "    temp_pairs.append((p[0], from_infix_to_prefix(p[1]), p[2], p[3]))\n",
    "pairs = temp_pairs\n",
    "\n",
    "train_fold, test_fold, valid_fold = get_train_test_fold(ori_path,prefix,data,pairs,group_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing words...\n",
      "keep_words 1346 / 3867 = 0.3481\n",
      "Indexed 1349 words in input language, 15 words in output\n",
      "Number of training data 5332\n",
      "Number of testind data 1334\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_acc_fold = []\n",
    "\n",
    "pairs_tested = test_fold\n",
    "#pairs_trained = valid_fold\n",
    "pairs_trained = train_fold\n",
    "\n",
    "#for fold_t in range(5):\n",
    "#    if fold_t == fold:\n",
    "#        pairs_tested += fold_pairs[fold_t]\n",
    "#    else:\n",
    "#        pairs_trained += fold_pairs[fold_t]\n",
    "\n",
    "input_lang, output_lang, train_pairs, test_pairs = prepare_data(pairs_trained, pairs_tested, 5, generate_nums,\n",
    "                                                                copy_nums, tree=True)\n",
    "\n",
    "#print('train_pairs[0]')\n",
    "#print(train_pairs[0])\n",
    "#exit()\n",
    "# Initialize models\n",
    "encoder = EncoderSeq(input_size=input_lang.n_words, embedding_size=embedding_size, hidden_size=hidden_size,\n",
    "                     n_layers=n_layers)\n",
    "predict = Prediction(hidden_size=hidden_size, op_nums=output_lang.n_words - copy_nums - 1 - len(generate_nums),\n",
    "                     input_size=len(generate_nums))\n",
    "generate = GenerateNode(hidden_size=hidden_size, op_nums=output_lang.n_words - copy_nums - 1 - len(generate_nums),\n",
    "                        embedding_size=embedding_size)\n",
    "merge = Merge(hidden_size=hidden_size, embedding_size=embedding_size)\n",
    "# the embedding layer is  only for generated number embeddings, operators, and paddings\n",
    "\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "predict_optimizer = torch.optim.Adam(predict.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "generate_optimizer = torch.optim.Adam(generate.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "merge_optimizer = torch.optim.Adam(merge.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "encoder_scheduler = torch.optim.lr_scheduler.StepLR(encoder_optimizer, step_size=20, gamma=0.5)\n",
    "predict_scheduler = torch.optim.lr_scheduler.StepLR(predict_optimizer, step_size=20, gamma=0.5)\n",
    "generate_scheduler = torch.optim.lr_scheduler.StepLR(generate_optimizer, step_size=20, gamma=0.5)\n",
    "merge_scheduler = torch.optim.lr_scheduler.StepLR(merge_optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    predict.cuda()\n",
    "    generate.cuda()\n",
    "    merge.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.load_state_dict(torch.load(\"model_traintest/encoder\"))\n",
    "predict.load_state_dict(torch.load(\"model_traintest/predict\"))\n",
    "generate.load_state_dict(torch.load(\"model_traintest/generate\"))\n",
    "merge.load_state_dict(torch.load(\"model_traintest/merge\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../generalization_data_test.json', encoding=\"utf-8\") as json_file:\n",
    "   data_test = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "data_by_type = defaultdict(list)\n",
    "\n",
    "for x in data_test:\n",
    "    data_by_type[x['type']].append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/337 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE:\n",
      "journey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [04:06<00:00,  1.37it/s]\n",
      "  0%|          | 0/383 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 115 337\n",
      "test_answer_acc 0.27299703264094954 0.34124629080118696\n",
      "testing time 0h 4m 6s\n",
      "------------------------------------------------------\n",
      "TYPE:\n",
      "relation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 383/383 [03:42<00:00,  1.72it/s]\n",
      "  0%|          | 0/382 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190 211 383\n",
      "test_answer_acc 0.4960835509138381 0.5509138381201044\n",
      "testing time 0h 3m 42s\n",
      "------------------------------------------------------\n",
      "TYPE:\n",
      "price\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [04:00<00:00,  1.59it/s]\n",
      "  0%|          | 0/232 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 160 382\n",
      "test_answer_acc 0.3219895287958115 0.418848167539267\n",
      "testing time 0h 4m 0s\n",
      "------------------------------------------------------\n",
      "TYPE:\n",
      "task_completion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [03:12<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 110 232\n",
      "test_answer_acc 0.33189655172413796 0.47413793103448276\n",
      "testing time 0h 3m 12s\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "generate_num_ids = []\n",
    "for num in generate_nums:\n",
    "    generate_num_ids.append(output_lang.word2index[num])\n",
    "\n",
    "for typ, ls in data_by_type.items():\n",
    "    print(\"TYPE:\")\n",
    "    print(typ)\n",
    "    value_ac = 0\n",
    "    equation_ac = 0\n",
    "    eval_total = 0\n",
    "    start = time.time()\n",
    "    \n",
    "    batches = {}\n",
    "    for test_batch in test_pairs:\n",
    "        batches[test_batch[8]] = test_batch\n",
    "        \n",
    "    for correct_data in tqdm(ls):\n",
    "        #print(test_batch)\n",
    "        test_batch = batches[correct_data['id']]\n",
    "        #print(test_batch)\n",
    "        batch_graph = get_single_example_graph(test_batch[0], test_batch[1], test_batch[7], test_batch[4], test_batch[5])\n",
    "        test_res = evaluate_tree(test_batch[0], test_batch[1], generate_num_ids, encoder, predict, generate,\n",
    "                                 merge, output_lang, test_batch[5], batch_graph, beam_size=beam_size)\n",
    "        val_ac, equ_ac, _, _ = compute_prefix_tree_result(test_res, test_batch[2], output_lang, test_batch[4], test_batch[6])\n",
    "        if val_ac:\n",
    "            value_ac += 1\n",
    "        if equ_ac:\n",
    "            equation_ac += 1\n",
    "        eval_total += 1\n",
    "    print(equation_ac, value_ac, eval_total)\n",
    "    print(\"test_answer_acc\", float(equation_ac) / eval_total, float(value_ac) / eval_total)\n",
    "    print(\"testing time\", time_since(time.time() - start))\n",
    "    print(\"------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([53,\n",
       "  140,\n",
       "  136,\n",
       "  12,\n",
       "  1190,\n",
       "  1006,\n",
       "  112,\n",
       "  13,\n",
       "  125,\n",
       "  206,\n",
       "  1,\n",
       "  117,\n",
       "  12,\n",
       "  128,\n",
       "  2,\n",
       "  130,\n",
       "  2,\n",
       "  68,\n",
       "  1,\n",
       "  125,\n",
       "  12,\n",
       "  1190,\n",
       "  153,\n",
       "  112,\n",
       "  13,\n",
       "  125,\n",
       "  206,\n",
       "  1,\n",
       "  117,\n",
       "  12,\n",
       "  1190,\n",
       "  153,\n",
       "  128,\n",
       "  2,\n",
       "  253,\n",
       "  2,\n",
       "  691,\n",
       "  75,\n",
       "  142,\n",
       "  21],\n",
       " 40,\n",
       " [2, 0, 6, 7, 8],\n",
       " 5,\n",
       " ['71', '12', '95'],\n",
       " [10, 18, 27],\n",
       " [],\n",
       " [15, 16, 17, 32, 33, 34, 39, 40, 41])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pairs[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
